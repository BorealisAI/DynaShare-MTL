exp_name: mimic_aig_targetrate_1.0_w_25_re-train0.3 #[mimic_aig_targetrate_1.0_w_25, mimic_aig_targetrate_w_25, mimic_aig_targetrate_0.4_w_25, mimic_aig_targetrate_0.4_w_100, mimic_resnet34_aig_targetrate_0.5_w_500]
seed: [88, 45, 50, 100, 44, 48, 2048, 2222, 23, 12, 94, 88, 1000, 42, 77, 666]
backbone: ResNet18 # ResNet34
#tasks: [ multilabel sequence classification (phenotyping), regression (length-of-stay, time-series), classification task (in-hospital Mortality), time-series classification (decompensation)]
tasks: ['pheno','los','decomp','ihm']  
tasks_num_class: [25, 10, 1, 1]
lambdas: [1, 2, 2, 1] #task weights
target_rates: [1, 1, 1, 1, 1, 1, 0.9, 1] # [1, 1, 1, 0.7, 0.7, 0.7, 0.7, 1] [1, 1, 1, 0.4, 0.4, 0.4, 0.4, 1], [1, 1, 1, 1, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1]
policy_model: AIG # options: task-specific(regular 1d), AIG, Dynamic, AIGDynamic

alpha: 0.00001 #decay downgrad
task_balance_method: 'None' #options: 'None', 'DWA', 'LBTW'

paths:
  log_dir: ../experiments/logs/
  result_dir: ../experiments/results
  checkpoint_dir: ../experiments/checkpoints


dataload:
  dataset: mimic
  dataroot: "/home/MTL/data/mimiciii"


policy: True
init_neg_logits:
is_sparse: True
is_sharing: True
skip_layer: 0
is_curriculum: True
curriculum_speed: 3
fix_BN: False
diff_sparsity_weights: True
retrain_from_pl: False


train:
  prop: 1.0 # proportion of training set used
  seqlen: 170
  batch_size: 256
  total_iters: 1000
  warm_up_iters: 500
  policy_learning_checking: 10
  lr: 0.001 # 0.001
  policy_lr: 0.01 #0.01
  backbone_lr: 0.001 #0.001
  reg_w: 0.001
  reg_w_hamming: 0.05
  targetrate_w: 25 #target rate loss weights [2,25,100]
  print_freq: 2
  val_freq: 10
  decay_lr_freq: 250
  decay_lr_rate: 0.5
  decay_temp_freq: 5
  init_temp: 5
  decay_temp: 0.965
  cw_pheno: 5.0 #class weights
  cw_decomp: 500.0
  cw_ihm: 5.0
  cw_los: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0] #[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]  # [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]
  resume: False #True 
  retrain_resume: False
  policy_iter: best # options: warmup, latest, best
  which_iter: latest #warmup
  init_method: equal
  hard_sampling: False
  

test:
  which_iter: best